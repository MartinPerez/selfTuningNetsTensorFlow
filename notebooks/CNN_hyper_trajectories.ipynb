{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model hyper experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 problem setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets consider the CIFAR10 dataset available in Tensorflow. https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take as reference the trivial example CNN from Tensorflow to extend it with dropout layers and display pixel dropout for data augmentation.\n",
    "\n",
    "We will implement a custom version of the following KERAS model: https://www.tensorflow.org/tutorials/images/cnn, enhanced with dropout.\n",
    "\n",
    "     model = models.Sequential()\n",
    "     model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "     model.add(layers.MaxPooling2D((2, 2)))\n",
    "     model.add(layers.Dropout(0.05))\n",
    "     model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "     model.add(layers.MaxPooling2D((2, 2)))\n",
    "     model.add(layers.Dropout(0.05))\n",
    "     model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "     model.add(layers.Flatten())\n",
    "     model.add(layers.Dropout(0.05))\n",
    "     model.add(layers.Dense(64, activation='relu'))\n",
    "     model.add(layers.Dense(10))\n",
    "     return model\n",
    "\n",
    "Hyperparameters:\n",
    "    * Network architecture (CNN)\n",
    "        * Dropout prob 1\n",
    "        * Dropout prob 2\n",
    "        * Dropout prob 3\n",
    "    * Data augmentation\n",
    "        * Prob to modify batch sample\n",
    "        * Pixel dropout prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero(train_labels == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "validation_samples = np.concatenate([rng.choice(np.nonzero(train_labels == i)[0], 1000, replace=False) for i in range(10)], axis=0)\n",
    "training_samples = np.setdiff1d(np.array(range(50000)), validation_samples, assume_unique=True)\n",
    "rng.shuffle(validation_samples)\n",
    "rng.shuffle(training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[training_samples].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment cache utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering experiments can take more than 15m to turn, here a small decorator function to store the experiment outputs if it does not fail. I rely on a frozen dataclass Config to hash the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import pickle\n",
    "\n",
    "def cache_results(exp_func, exp_dir=\"cnn_experiments\"):\n",
    "    def cached(*args):\n",
    "        config = args[0]\n",
    "        cache_dir = hashlib.md5(str.encode(str(config.__hash__()))).hexdigest()\n",
    "        results_dir = f'_cache/{exp_dir}/{cache_dir}'\n",
    "        if not os.path.exists(results_dir):\n",
    "            os.makedirs(results_dir)\n",
    "        exp_results_file = f'{results_dir}/results.pkl'\n",
    "        if os.path.exists(exp_results_file):\n",
    "            print(\"results loaded from cache for: \", config)\n",
    "            with open(exp_results_file, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        results = exp_func(*args)\n",
    "        with open(exp_results_file, 'wb') as f:\n",
    "            pickle.dump(results, f)\n",
    "        return results\n",
    "    return cached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN hyper training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from self_tuning_nets.visualization import function_animation, trajectories_plot, \\\n",
    "    trajectories_legend, trajectories_dist_from_target, trajectories_general_plot\n",
    "from self_tuning_nets.hyper.experiments.cnn_models import \\\n",
    "    ExperimentConfig, run_deterministic_cpu_hyper_cnn_experiment\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from self_tuning_nets.visualization import function_animation, trajectories_plot, \\\n",
    "    trajectories_legend, trajectories_dist_from_target, trajectories_general_plot\n",
    "from dataclasses import replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config = ExperimentConfig()\n",
    "wlosses, hlosses, param_trajectories, scale_trajectories, accuracy = \\\n",
    "cache_results(run_deterministic_cpu_hyper_cnn_experiment)(experiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracy)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "print(\"Accuracy: \", max(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wlosses, label=\"w_loss\")\n",
    "plt.plot(hlosses, label=\"h_loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_palette = [plt.get_cmap('Reds')(x) for x in np.linspace(0.3, 1.0, num=len(param_trajectories.keys()))]\n",
    "trajectories_legend(param_trajectories.keys(), lines_palette)\n",
    "plt.gcf().set_size_inches(1,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = [param_trajectories[k] for k in param_trajectories.keys()]\n",
    "trajectories_general_plot(trajectories, lines_palette, ylabel=\"probabilities\")\n",
    "plt.show()\n",
    "trajectories = [scale_trajectories[k] for k in param_trajectories.keys()]\n",
    "trajectories_general_plot(trajectories, lines_palette, ylabel=\"scaling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Fixed hyperparameters example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config = ExperimentConfig(WITH_HYPER_TRAINING=False)\n",
    "wlosses, hlosses, param_trajectories, scale_trajectories, accuracy = \\\n",
    "cache_results(run_deterministic_cpu_hyper_cnn_experiment)(experiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracy)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "print(\"Accuracy: \", max(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wlosses, label=\"w_loss\")\n",
    "assert not hlosses\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_palette = [plt.get_cmap('Reds')(x) for x in np.linspace(0.3, 1.0, num=len(param_trajectories.keys()))]\n",
    "trajectories_legend(param_trajectories.keys(), lines_palette)\n",
    "plt.gcf().set_size_inches(1,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = [param_trajectories[k] for k in param_trajectories.keys()]\n",
    "trajectories_general_plot(trajectories, lines_palette, ylabel=\"probabilities\")\n",
    "plt.show()\n",
    "trajectories = [scale_trajectories[k] for k in param_trajectories.keys()]\n",
    "trajectories_general_plot(trajectories, lines_palette, ylabel=\"scaling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config = ExperimentConfig()\n",
    "sample_seeds = range(40, 48)\n",
    "# sample_seeds = range(40, 42)\n",
    "results = [\n",
    "    cache_results(run_deterministic_cpu_hyper_cnn_experiment)(\n",
    "        replace(experiment_config,\n",
    "                FRAMEWORK_SEED=sample_seed,\n",
    "                MAX_EPOCHS=20\n",
    "               ))\n",
    "    for sample_seed in sample_seeds\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlosses_n, hlosses_n, param_trajectories_n, scale_trajectories_n, accuracy_n = \\\n",
    "zip(*results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = [max(acc) for acc in accuracy_n]\n",
    "rescaled_acc = [0.3 + ((1 - 0.3) / (max(best_acc) - min(best_acc))) * (acc - min(best_acc)) for acc in best_acc]\n",
    "lines_palette = [plt.get_cmap('Reds')(acc) for acc in rescaled_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_info = sorted(zip(lines_palette, sample_seeds, best_acc), key=lambda x: x[2])\n",
    "sorted_settings = [f\"Acc: {acc:.{3}f} -> Param: {param}\" for _, param, acc in sorted_info]\n",
    "sorted_palette = [palette for palette, _, _ in sorted_info]\n",
    "print(\"Accuracy -> init_seed\")\n",
    "trajectories_legend(sorted_settings, sorted_palette)\n",
    "plt.gcf().set_size_inches(1.0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "mappable = cm.ScalarMappable(cmap=plt.get_cmap('Reds'))\n",
    "mappable.set_clim(vmin=np.min(best_acc), vmax=np.max(best_acc))\n",
    "plt.colorbar(mappable, ax=plt.gca(), orientation='horizontal')\n",
    "plt.gca().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_general_plot(accuracy_n, lines_palette, ylabel=\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_keys = param_trajectories_n[0].keys()\n",
    "for pk in param_keys:\n",
    "    trajectories = [param_t[pk] for param_t in param_trajectories_n]\n",
    "    trajectories_general_plot(trajectories, lines_palette, ylabel=\"probabilities\", title=pk)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration of converging hyperparameter trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config = ExperimentConfig()\n",
    "sample_seeds = [40, 42, 44]\n",
    "# sample_seeds = [44]\n",
    "init_hyper = [(0.95, 0.95, 0.05), (0.75, 0.75, 0.2), (0.5, 0.5, 0.5), (0.3, 0.3, 0.8),\n",
    "              (0.8145, 0.9818, 0.5502), (0.5466, 0.2618, 0.8580)]\n",
    "\n",
    "exp_settings = list(product(sample_seeds, init_hyper))\n",
    "results = [\n",
    "    cache_results(run_deterministic_cpu_hyper_cnn_experiment)(\n",
    "        replace(experiment_config,\n",
    "                FRAMEWORK_SEED=sample_seed,\n",
    "                INIT_DROPOUT=init_drop,\n",
    "                INIT_PIXEL_DROPOUT=init_drop,\n",
    "                INIT_AUGMENT_PROB=init_aug,\n",
    "                MAX_EPOCHS=40\n",
    "               ))\n",
    "    for sample_seed, (init_drop, init_pixel, init_aug) in exp_settings\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlosses_n, hlosses_n, param_trajectories_n, scale_trajectories_n, accuracy_n = \\\n",
    "zip(*results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = [max(acc) for acc in accuracy_n]\n",
    "rescaled_acc = [0.3 + ((1 - 0.3) / (max(best_acc) - min(best_acc))) * (acc - min(best_acc)) for acc in best_acc]\n",
    "lines_palette = [plt.get_cmap('Reds')(acc) for acc in rescaled_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_info = sorted(zip(lines_palette, exp_settings, best_acc), key=lambda x: x[2])\n",
    "sorted_settings = [f\"Acc: {acc:.{3}f} -> Param: {param}\" for _, param, acc in sorted_info]\n",
    "sorted_palette = [palette for palette, _, _ in sorted_info]\n",
    "print(\"Accuracy -> (init_seed, (layer_keepin_prob (1 - dropout), pixel_keepin_prob (1 - dropout), augment_image_prob))\")\n",
    "trajectories_legend(sorted_settings, sorted_palette)\n",
    "plt.gcf().set_size_inches(1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "mappable = cm.ScalarMappable(cmap=plt.get_cmap('Reds'))\n",
    "mappable.set_clim(vmin=np.min(best_acc), vmax=np.max(best_acc))\n",
    "plt.colorbar(mappable, ax=plt.gca(), orientation='horizontal')\n",
    "plt.gca().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_general_plot(accuracy_n, lines_palette, ylabel=\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "param_keys = param_trajectories_n[0].keys()\n",
    "print(f\"Final hyperparameter values for network with best accuracy {np.max(best_acc):.{3}f}\")\n",
    "for pk in param_keys:\n",
    "    print(pk, \": \", param_trajectories_n[np.argmax(best_acc)][pk][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "param_keys = param_trajectories_n[0].keys()\n",
    "print(f\"Final hyperparameter values for network with worst accuracy {np.min(best_acc):.{3}f}\")\n",
    "for pk in param_keys:\n",
    "    print(pk, \": \", param_trajectories_n[np.argmin(best_acc)][pk][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_keys = param_trajectories_n[0].keys()\n",
    "for pk in param_keys:\n",
    "    trajectories = [param_t[pk] for param_t in param_trajectories_n]\n",
    "    trajectories_general_plot(trajectories, lines_palette, ylabel=\"Bernoulli probability\", title=pk)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_keys = scale_trajectories_n[0].keys()\n",
    "for pk in param_keys:\n",
    "    trajectories = [scale_t[pk] for scale_t in scale_trajectories_n]\n",
    "    trajectories_general_plot(trajectories, lines_palette, ylabel=\"scales\", title=pk)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
