{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO example for CIFAR10 Custom CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 problem setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets consider the CIFAR10 dataset available in Tensorflow. https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take as reference the trivial example CNN from Tensorflow to extend it with dropout layers and display pixel dropout for data augmentation.\n",
    "\n",
    "We will implement a custom version of the following KERAS model: https://www.tensorflow.org/tutorials/images/cnn, enhanced with dropout.\n",
    "\n",
    "     model = models.Sequential()\n",
    "     model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "     model.add(layers.MaxPooling2D((2, 2)))\n",
    "     model.add(layers.Dropout(0.05))\n",
    "     model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "     model.add(layers.MaxPooling2D((2, 2)))\n",
    "     model.add(layers.Dropout(0.05))\n",
    "     model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "     model.add(layers.Flatten())\n",
    "     model.add(layers.Dropout(0.05))\n",
    "     model.add(layers.Dense(64, activation='relu'))\n",
    "     model.add(layers.Dense(10))\n",
    "     return model\n",
    "\n",
    "Hyperparameters:\n",
    "    * Network architecture (CNN)\n",
    "        * Dropout prob 1\n",
    "        * Dropout prob 2\n",
    "        * Dropout prob 3\n",
    "    * Data augmentation\n",
    "        * Prob to modify batch sample\n",
    "        * Pixel dropout prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero(train_labels == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "validation_samples = np.concatenate([rng.choice(np.nonzero(train_labels == i)[0], 1000, replace=False) for i in range(10)], axis=0)\n",
    "training_samples = np.setdiff1d(np.array(range(50000)), validation_samples, assume_unique=True)\n",
    "rng.shuffle(validation_samples)\n",
    "rng.shuffle(training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[training_samples].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment cache utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering experiments can take more than 15m to turn, here a small decorator function to store the experiment outputs if it does not fail. I rely on a frozen dataclass Config to hash the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import pickle\n",
    "\n",
    "def cache_results(exp_func, exp_dir=\"cnn_experiments\"):\n",
    "    def cached(*args, **kwargs):\n",
    "        config = args[0]\n",
    "        cache_dir = hashlib.md5(str.encode(str(config.__hash__()))).hexdigest()\n",
    "        results_dir = f'_cache/{exp_dir}/{cache_dir}'\n",
    "        if not os.path.exists(results_dir):\n",
    "            os.makedirs(results_dir)\n",
    "        exp_results_file = f'{results_dir}/results.pkl'\n",
    "        if os.path.exists(exp_results_file):\n",
    "            print(\"results loaded from cache for: \", config)\n",
    "            with open(exp_results_file, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        results = exp_func(*args, **kwargs)\n",
    "        with open(exp_results_file, 'wb') as f:\n",
    "            pickle.dump(results, f)\n",
    "        return results\n",
    "    return cached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential hyper parameter tuning with annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpo import Experiment\n",
    "from hpo.optimizers import Anneal, GridSearch, RandomSearch, GaussianProcess\n",
    "from hpo.runtimes import Local\n",
    "from hpo.space import Real, Integer, Quantized, Choice, SearchSpace\n",
    "from self_tuning_nets.visualization import trajectories_legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(args):\n",
    "    experiment_config = ExperimentConfig(\n",
    "        INIT_DROPOUT=args.get(\"init_dropout\", 0.95),\n",
    "        INIT_PIXEL_DROPOUT=args.get(\"init_pixel_dropout\", 0.95),\n",
    "        INIT_AUGMENT_PROB=args.get(\"init_augment_prob\", 0.05),\n",
    "        WITH_HYPER_TRAINING=False,\n",
    "        MAX_EPOCHS=40)\n",
    "    wlosses, hlosses, param_trajectories, scale_trajectories, accuracy, hyper_accuracy = \\\n",
    "    cache_results(run_deterministic_cpu_hyper_cnn_experiment, \"hpo_cnn\")(experiment_config, for_hpo=True)\n",
    "    print(-hyper_accuracy)\n",
    "    return {\n",
    "        \"loss\": -float(hyper_accuracy),\n",
    "        \"wlosses\": wlosses,\n",
    "        \"hlosses\": hlosses,\n",
    "        \"param_trajectories\": param_trajectories,\n",
    "        \"scale_trajectories\": scale_trajectories,\n",
    "        \"accuracy\": accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can not cache models for anneal since it does not let us modify the seed\n",
    "# So instead we save the full results and avoid rerunning\n",
    "def recover_anneal_results():\n",
    "    results_dir = f'_cache/hpo_cnn/anneal_results1'\n",
    "    exp_results_file = f'{results_dir}/results.pkl'\n",
    "    if os.path.exists(exp_results_file):\n",
    "        with open(exp_results_file, 'rb') as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recover_anneal_results() is None:\n",
    "    optimizer = Anneal()\n",
    "    space = SearchSpace(\n",
    "        init_dropout=Real(start=0.25, end=1.0),\n",
    "        init_pixel_dropout=Real(start=0.25, end=1.0),\n",
    "        init_augment_prob=Real(start=0.0, end=0.95)\n",
    "    )\n",
    "    # number_of_trials = space.size\n",
    "    number_of_trials = 20\n",
    "    exp = Experiment(\n",
    "       name=\"hpo_cnn\",\n",
    "       target=run_model,\n",
    "       search_space=space,\n",
    "       optimizer=optimizer,\n",
    "       trials=number_of_trials)\n",
    "    \n",
    "    runtime = Local(njobs=1)\n",
    "    res = runtime.run(exp)\n",
    "\n",
    "    results_dir = f'_cache/hpo_cnn/anneal_results1'\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    exp_results_file = f'{results_dir}/results.pkl'\n",
    "    with open(exp_results_file, 'wb') as f:\n",
    "        pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anneal_results = recover_anneal_results()\n",
    "print(f\"Best model Hyperparam {anneal_results.x} -> Test acc: {anneal_results.y['accuracy'][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [(r[\"wlosses\"], r[\"hlosses\"], r[\"param_trajectories\"], r[\"scale_trajectories\"], r[\"accuracy\"]) for r in anneal_results.y_iters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlosses_n, hlosses_n, param_trajectories_n, scale_trajectories_n, accuracy_n = \\\n",
    "zip(*results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = [acc[-1] for acc in accuracy_n]\n",
    "rescaled_acc = [0.3 + ((1 - 0.3) / (max(best_acc) - min(best_acc))) * (acc - min(best_acc)) for acc in best_acc]\n",
    "lines_palette = [plt.get_cmap('Reds')(acc) for acc in rescaled_acc]\n",
    "print(\"Best acc: \", max(best_acc))\n",
    "print(\"Worst acc: \", min(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anneal_results.x_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_settings = anneal_results.x_iters\n",
    "sorted_info = sorted(zip(lines_palette, exp_settings, best_acc), key=lambda x: x[2])\n",
    "sorted_settings = [f\"Acc: {acc:.{3}f} -> Param: {param}\" for _, param, acc in sorted_info]\n",
    "sorted_palette = [palette for palette, _, _ in sorted_info]\n",
    "print(\"Accuracy -> param dict\")\n",
    "trajectories_legend(sorted_settings, sorted_palette)\n",
    "plt.gcf().set_size_inches(1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "mappable = cm.ScalarMappable(cmap=plt.get_cmap('Reds'))\n",
    "mappable.set_clim(vmin=np.min(best_acc), vmax=np.max(best_acc))\n",
    "plt.colorbar(mappable, ax=plt.gca(), orientation='horizontal')\n",
    "plt.gca().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=[x[0][1] for x in exp_settings], y=[x[1][1] for x in exp_settings], color=lines_palette)\n",
    "plt.xlabel(\"augment_prob\")\n",
    "plt.ylabel(\"layer_dropout\")\n",
    "plt.show()\n",
    "plt.scatter(x=[x[2][1] for x in exp_settings], y=[x[1][1] for x in exp_settings], color=lines_palette)\n",
    "plt.xlabel(\"pixel_dropout\")\n",
    "plt.ylabel(\"layer_dropout\")\n",
    "plt.show()\n",
    "plt.scatter(x=[x[2][1] for x in exp_settings], y=[x[0][1] for x in exp_settings], color=lines_palette)\n",
    "plt.xlabel(\"pixel_dropout\")\n",
    "plt.ylabel(\"augment_prob\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_general_plot(accuracy_n, lines_palette, ylabel=\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "param_keys = param_trajectories_n[0].keys()\n",
    "print(\"Best hyperparam with test acc: \", best_acc[np.argmax(best_acc)])\n",
    "for pk in param_keys:\n",
    "    print(pk, \": \", param_trajectories_n[np.argmax(best_acc)][pk][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "param_keys = param_trajectories_n[0].keys()\n",
    "print(\"Worst hyperparam with test acc: \", best_acc[np.argmin(best_acc)])\n",
    "for pk in param_keys:\n",
    "    print(pk, \": \", param_trajectories_n[np.argmin(best_acc)][pk][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
