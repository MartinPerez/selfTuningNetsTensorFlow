{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Fixed hyperparam comparison of pytorch and tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to test the self tuning network proposal of MacKay et al in https://arxiv.org/pdf/1903.03088.pdf in the simplest setting possible. Such that we can verify basic behaviors expected from the method parallely on the provided pytorch implementation and a tensorflow implementation to be used on other networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy problem setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets consider a simple analytical function to be learned by a network architecture.\n",
    "\n",
    "y = f(x) = x^2\n",
    "\n",
    "From the work of Weinan et al https://arxiv.org/pdf/1807.00297.pdf,  \n",
    "we expect that a Deep Relu network with:  \n",
    "- depth = L + 1  \n",
    "- width = M + d + 1\n",
    "\n",
    "where d is the dimensionality of x contained in [-1, 1], L is a positive integer and M = 2,  \n",
    "that we can eventually find a function g for which  \n",
    "- sup|g(x) - f(x)| < 2^(-2L)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the work of MacKay et al as presented in https://arxiv.org/pdf/1903.03088.pdf, we can only fine tune hyperparameters that constraint the training loss and so constraint the weights/parameters of the network directly or indirectly during the training process. Examples of these type of hyperparameters can be:\n",
    "- data modification/augmentation parameters like masks applied to image data or weighting data samples\n",
    "- l1 and l2 regularization of the loss function\n",
    "- functions that apply on weight/parameters like dropout. Notice that since the method proposed operates on expectation it is possible to take into account hyperparameters with stochastic effects like dropout.\n",
    "\n",
    "Examples of hyperparameter cases not covered:\n",
    "- When the validation loss is impacted as well like by changing the number of neurons. Notice dropout is not supposed to be used during validation and the loss would not be subject ot the l1 or l2 regularizations of weights on training.\n",
    "- When the parameter is linked to the optimization procedure itself, like the learning rate of any optimizer employed.\n",
    "\n",
    "For this toy problem we propose to verify the effect of the x_range trivial hyperparameter where:\n",
    "- We have a training randomly uniformly sampled interval [-t, t]\n",
    "- To evaluate the function on equally spaced segments of an interval [-e, e]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from self_tuning_nets.linear_experiment import \\\n",
    "    ExperimentConfig, run_deterministic_cpu_basic_torch_experiment\n",
    "\n",
    "experiment_config = ExperimentConfig()\n",
    "X_eval = np.expand_dims(np.linspace(\n",
    "    -experiment_config.EVAL_RANGE,\n",
    "    experiment_config.EVAL_RANGE,\n",
    "    experiment_config.EVAL_SIZE), 1)\n",
    "\n",
    "f_trajectory = run_deterministic_cpu_basic_torch_experiment(experiment_config, X_eval, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from self_tuning_nets.visualization import function_animation\n",
    "function_animation(X_eval, [f_trajectory], [\"b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from self_tuning_nets.linear_experiment import \\\n",
    "    ExperimentConfig, run_deterministic_cpu_basic_torch_experiment\n",
    "\n",
    "experiment_config = ExperimentConfig()\n",
    "X_eval = np.expand_dims(np.linspace(\n",
    "    -experiment_config.EVAL_RANGE,\n",
    "    experiment_config.EVAL_RANGE,\n",
    "    experiment_config.EVAL_SIZE), 1)\n",
    "experiment_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import replace\n",
    "\n",
    "SAMPLING_SPEED = 100\n",
    "function_trajectories = [\n",
    "    run_deterministic_cpu_basic_torch_experiment(\n",
    "        replace(experiment_config,\n",
    "                WEIGHTS_SEED=sample_seed,\n",
    "                PRED_SAMPLING_STEP=SAMPLING_SPEED),\n",
    "        X_eval)\n",
    "    for sample_seed in range(40, 50)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from self_tuning_nets.visualization import function_animation\n",
    "\n",
    "lines_palette = [plt.get_cmap(\"viridis\")(i) for i in np.linspace(0, 0.7, len(function_trajectories))]\n",
    "function_animation(X_eval, function_trajectories, lines_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from self_tuning_nets.visualization import trajectories_plot, trajectories_legend, trajectories_dist_from_target\n",
    "\n",
    "trajectories_distances = trajectories_dist_from_target(function_trajectories, X_eval ** 2, 100)\n",
    "trajectories_plot(trajectories_distances, lines_palette, SAMPLING_SPEED, title_extra=\"weights\")\n",
    "plt.show()\n",
    "trajectories_legend(range(40, 50), lines_palette)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import replace\n",
    "from itertools import product\n",
    "\n",
    "SAMPLING_SPEED = 1\n",
    "MAX_BATCHES=400\n",
    "function_trajectories = [\n",
    "    run_deterministic_cpu_basic_torch_experiment(\n",
    "        replace(experiment_config,\n",
    "                WEIGHTS_SEED=weight_seed,\n",
    "                DATA_SEED=data_seed,\n",
    "                PRED_SAMPLING_STEP=SAMPLING_SPEED,\n",
    "                MAX_BATCHES=MAX_BATCHES),\n",
    "        X_eval)\n",
    "    for weight_seed, data_seed in list(product([40, 45, 47], [42, 43, 44, 45]))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from self_tuning_nets.visualization import trajectories_plot, trajectories_legend, trajectories_dist_from_target\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lines_palette = [plt.get_cmap(\"viridis\")(i) for i in np.linspace(0, 0.7, len(function_trajectories))]\n",
    "trajectories_distances = trajectories_dist_from_target(function_trajectories, X_eval ** 2, 100)\n",
    "trajectories_plot(trajectories_distances, lines_palette, SAMPLING_SPEED, title_extra=\"(weights, data)\")\n",
    "plt.show()\n",
    "trajectories_legend(list(product([40, 45, 47], [42, 43, 44, 45])), lines_palette)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed hyperparameter experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import replace\n",
    "\n",
    "SAMPLING_SPEED = 1\n",
    "MAX_BATCHES = 2000\n",
    "function_trajectories = [\n",
    "    run_deterministic_cpu_basic_torch_experiment(\n",
    "        replace(experiment_config,\n",
    "                WEIGHTS_SEED=40,\n",
    "                TRAIN_RANGE=train_range,\n",
    "                PRED_SAMPLING_STEP=SAMPLING_SPEED,\n",
    "                MAX_BATCHES=MAX_BATCHES),\n",
    "        X_eval)\n",
    "    for train_range in [4.0, 3.0, 2.5, 2.0, 1.5, 1.0, 0.5, 0.25]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from self_tuning_nets.visualization import trajectories_plot, trajectories_legend, trajectories_dist_from_target\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lines_palette = [plt.get_cmap(\"viridis\")(i) for i in np.linspace(0, 0.7, len(function_trajectories))]\n",
    "trajectories_distances = trajectories_dist_from_target(function_trajectories, X_eval ** 2, 100)\n",
    "trajectories_plot(trajectories_distances, lines_palette, SAMPLING_SPEED, title_extra=\"X max abs value\\nEval max abs value of 1\")\n",
    "plt.show()\n",
    "trajectories_legend([4.0, 3.0, 2.5, 2.0, 1.5, 1.0, 0.5, 0.25], lines_palette)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from self_tuning_nets.linear_experiment import \\\n",
    "    ExperimentConfig, run_deterministic_cpu_basic_keras_experiment\n",
    "\n",
    "experiment_config = ExperimentConfig()\n",
    "X_eval = np.expand_dims(np.linspace(\n",
    "    -experiment_config.EVAL_RANGE,\n",
    "    experiment_config.EVAL_RANGE,\n",
    "    experiment_config.EVAL_SIZE), 1)\n",
    "\n",
    "f_trajectory = run_deterministic_cpu_basic_keras_experiment(experiment_config, X_eval, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from self_tuning_nets.visualization import function_animation\n",
    "function_animation(X_eval, [f_trajectory], [\"b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed hyperparameter experiment reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import replace\n",
    "\n",
    "SAMPLING_SPEED = 1\n",
    "MAX_BATCHES = 1000\n",
    "function_trajectories = [\n",
    "    run_deterministic_cpu_basic_keras_experiment(\n",
    "        replace(experiment_config,\n",
    "                WEIGHTS_SEED=40,\n",
    "                TRAIN_RANGE=train_range,\n",
    "                PRED_SAMPLING_STEP=SAMPLING_SPEED,\n",
    "                MAX_BATCHES=MAX_BATCHES),\n",
    "        X_eval)\n",
    "    for train_range in [4.0, 3.0, 2.5, 2.0, 1.5, 1.0, 0.5, 0.25]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from self_tuning_nets.visualization import trajectories_plot, trajectories_legend, trajectories_dist_from_target\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lines_palette = [plt.get_cmap(\"viridis\")(i) for i in np.linspace(0, 0.7, len(function_trajectories))]\n",
    "trajectories_distances = trajectories_dist_from_target(function_trajectories, X_eval ** 2, 100)\n",
    "trajectories_plot(trajectories_distances, lines_palette, SAMPLING_SPEED, title_extra=\"X max abs value\\nEval max abs value of 1\")\n",
    "plt.show()\n",
    "trajectories_legend([4.0, 3.0, 2.5, 2.0, 1.5, 1.0, 0.5, 0.25], lines_palette)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
